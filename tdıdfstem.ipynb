{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0357b5c6-937c-4dee-8245-a0bffb81f6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem edilmiş cümleler için TF-IDF hesaplandı ve dosyaya kaydedildi.\n",
      "\n",
      "--- TF-IDF Matrisi İlk 5 Satır ---\n",
      "   aarp   ac  academi  acceler  access  accessori  accord  account  accumul  \\\n",
      "0   0.0  0.0      0.0      0.0     0.0        0.0     0.0      0.0      0.0   \n",
      "1   0.0  0.0      0.0      0.0     0.0        0.0     0.0      0.0      0.0   \n",
      "2   0.0  0.0      0.0      0.0     0.0        0.0     0.0      0.0      0.0   \n",
      "3   0.0  0.0      0.0      0.0     0.0        0.0     0.0      0.0      0.0   \n",
      "4   0.0  0.0      0.0      0.0     0.0        0.0     0.0      0.0      0.0   \n",
      "\n",
      "   ace  ...  www  xtream  year  yeti  yield  york  young  youtub  ziel  αρεχ  \n",
      "0  0.0  ...  0.0     0.0   0.0   0.0    0.0   0.0    0.0     0.0   0.0   0.0  \n",
      "1  0.0  ...  0.0     0.0   0.0   0.0    0.0   0.0    0.0     0.0   0.0   0.0  \n",
      "2  0.0  ...  0.0     0.0   0.0   0.0    0.0   0.0    0.0     0.0   0.0   0.0  \n",
      "3  0.0  ...  0.0     0.0   0.0   0.0    0.0   0.0    0.0     0.0   0.0   0.0  \n",
      "4  0.0  ...  0.0     0.0   0.0   0.0    0.0   0.0    0.0     0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv(\"stemlenmis_yorumlar.csv\")\n",
    "\n",
    "def temizle_ve_duzleştir(x):\n",
    "    try:\n",
    "        liste = eval(str(x))\n",
    "        if all(isinstance(i, list) for i in liste):\n",
    "            return [item for alt in liste for item in alt]\n",
    "        return liste\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "token_liste = df[\"stemlenmis_cümleler\"].apply(temizle_ve_duzleştir)\n",
    "\n",
    "stemmed_texts = [' '.join(tokens) for tokens in token_liste]\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf.fit_transform(stemmed_texts)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "tfidf_df.to_csv(\"tfidf_stemmed_yorumlar.csv\", index=False)\n",
    "print(\"Stem edilmiş cümleler için TF-IDF hesaplandı ve dosyaya kaydedildi.\")\n",
    "print(\"\\n--- TF-IDF Matrisi İlk 5 Satır ---\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a196b-7a2c-455e-97eb-058aa0f9e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d144ae51-331b-4825-8cc6-f98b83236cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c12240a3-c42b-42ae-9903-dcb0c29f9cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de825dd2-d05f-474e-aa58-0a971484bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            cümleler  \\\n",
      "0  ['Up to\\n$100 off\\nroundtrip\\nflights to\\nIrel...   \n",
      "1  ['yp The Real\\nур\\nYellow Pages\\nFind cheap\\ng...   \n",
      "2  ['Food Navigator\\nUSA\\nPlant-based meat:\\nBeyo...   \n",
      "3  [\"MONSTROUS\\nAIRFLOW\\n$20-$23\\nDURAMAX\\nbanks\\...   \n",
      "4  ['YUMMY\\nCOMBS\\n*\\na\\nNutriti\\nWellne\\nNOW\\nSa...   \n",
      "\n",
      "                                temizlenmis_cümleler  \n",
      "0  [[roundtrip, flights, ireland], [travel, terms...  \n",
      "1  [[yp, real, ур, yellow, pages, find, cheap, ga...  \n",
      "2  [[food, navigator, usa, meat, beyond, honeymoo...  \n",
      "3  [[monstrous, airflow, duramax, banks, bigger, ...  \n",
      "4  [[yummy, combs, nutriti, wellne, safest, nutri...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "dosya_yolu= pd.read_csv('cumlelere_ayrilmis_yorumlar.csv')\n",
    "\n",
    "\n",
    "def temizle_cumleler(cumle_listesi):\n",
    "    temiz_cumleler = []\n",
    "    for cumle in eval(str(cumle_listesi)):\n",
    "        tokens = word_tokenize(cumle.lower())\n",
    "        temiz = [\n",
    "            ''.join(ch for ch in token if ch not in punctuations)\n",
    "            for token in tokens\n",
    "            if token.isalpha() and token not in stop_words\n",
    "        ]\n",
    "        temiz_cumleler.append([kelime for kelime in temiz if kelime])\n",
    "    return temiz_cumleler\n",
    "\n",
    "dosya_yolu['temizlenmis_cümleler'] = dosya_yolu['cümleler'].apply(temizle_cumleler)\n",
    "\n",
    "\n",
    "print(dosya_yolu[['cümleler', 'temizlenmis_cümleler']].head())\n",
    "dosya_yolu.to_csv('temizlenmis_cümleler.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27736489-aebf-4a74-9f04-f6d3e9581713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
